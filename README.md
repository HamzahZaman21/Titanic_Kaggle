# Titanic_Kaggle
This notebook contains the code I used to get a score of 0.79186 (TOP 5%) on the Titanic-Machine Learning from Disaster Kaggle Competition (https://www.kaggle.com/competitions/titanic) . Sources I used are outlined below. 

Steps:

1.) Performed Exploratory Data Analysis(EDA) to understand the data set more.
2.) After EDA was complete, preprocessed the data to make it easier to train on
3.) Perfomed classification using Random Forest Classifier, Logistic Regression, SVM, XGBoost, and LightGBM
4.) Performed hypertuning using Bayes Search CV
5.) Perfomed additional hypertuning to find optimum probability threashold
6.) Performed preprocessing steps on the test data and made predictions
7.) Created the submitted file

Kaggle Profiel: https://www.kaggle.com/hamzah821

Sources:
https://www.kaggle.com/code/anandhuh/titanic-simple-solution-top-12 
https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge/blob/master/article_1.ipynb
https://www.kaggle.com/code/sathyanarayanrao89/factor-analysis-and-svm-predictions

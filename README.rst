=========================================================
Titanic - Machine Learning from Disaster - Kaggle Project
=========================================================






This notebook contains the code I used to get a score of 0.79186 (TOP 5%) on the Titanic-Machine Learning from Disaster Kaggle Competition. Sources I used are outlined below.  Steps:  1.) Performed Exploratory Data Analysis(EDA) to understand the data set more. 2.) After EDA was complete, preprocessed the data to make it easier to train on 3.) Perfomed classification using Random Forest Classifier, Logistic Regression, SVM, XGBoost, and LightGBM 4.) Performed hypertuning using Bayes Search CV 5.) Perfomed additional hypertuning to find optimum probability threashold 6.) Performed preprocessing steps on the test data and made predictions 7.) Created the submitted file  Sources: https://www.kaggle.com/code/anandhuh/titanic-simple-solution-top-12 https://github.com/ahmedbesbes/How-to-score-0.8134-in-Titanic-Kaggle-Challenge/blob/master/article_1.ipynb https://www.kaggle.com/code/sathyanarayanrao89/factor-analysis-and-svm-predictions



Features
--------

* TODO

Credits
-------

This package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.

.. _Cookiecutter: https://github.com/audreyr/cookiecutter
.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage
